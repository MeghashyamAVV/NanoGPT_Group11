# NanoGPT
We are working on a minimal but fully functional PyTorch implementation of GPT to understand the architecture and training workflow on at the code level while training the model on a small dataset. We conduct hyperparameter experiments, analyse both quantitative metrics and quantitative outputs. 
